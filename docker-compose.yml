services:
  wan2.1-antonio:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: wan2.1-practica-antonio
    image: wan2.1-antonio:latest
    
    # GPU support (using runtime for compatibility)
    runtime: nvidia
    
    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # CUDA_VISIBLE_DEVICES will be set automatically by docker-entrypoint.sh
      # based on GPU with highest available memory
      - PYTHONUNBUFFERED=1
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda-12.8/lib64:/usr/lib/x86_64-linux-gnu
    
    # Volume mounts
    volumes:
      # Mount code directory for easy editing
      - ./codigo:/app/codigo
      # Mount results directory to persist generated videos (host: /home/202111068/workdata/results)
      - /home/202111068/workdata/results:/app/resultados
      # Mount models directory to persist downloaded models (host: /home/202111068/workdata/models)
      - /home/202111068/workdata/models:/app/models
      # Mount Wan2.1 repository (will be cloned if not exists)
      - ./Wan2.1:/app/Wan2.1
      # Mount cache for Hugging Face models
      - ./cache:/app/.cache
      # Mount resources
      - ./recursos:/app/recursos
      # Mount instructions
      - ./instrucciones:/app/instrucciones
      # Optional: Mount host CUDA libraries (if needed)
      # - /usr/local/cuda-12.8:/usr/local/cuda-12.8:ro
    
    # Working directory
    working_dir: /app
    
    # Keep container running
    stdin_open: true
    tty: true
    #ports:
    #  - "8888:8888"
    #command: jupyter notebook --ip=0.0.0.0 --no-browser --allow-root
    # Network mode (optional, can be removed if not needed)
    network_mode: bridge
    
    # Restart policy
    restart: unless-stopped

